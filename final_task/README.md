# Итоговое задание по MLOps
Предсказание вида ириса по размерам чашелистика и лепестка
# Структура

```
.dvc/ # Содержит конфигурцию dvc
Dockerfile # Определяет параметры сборки образа
final_task/ # Корневая директория задания
|
├── jenkins_pipeline.txt # Скрипт пайплайна
│
├── pipeline.png # Визуальное представление пайплайна
│
├── jenkins_jobs/ # Содержит выполняемый код для каждой стадии 
│
├── backend/ # Содержит код и наборы данных для корректной работы веб-сервиса
|   ├── __init.py__ # Определяет директорию как модуль для импорта
│   ├── data/ # Содержит мета-данные датасетов для работы dvc 
│   │   ├── iris_dataset.csv # Модифицированный набор данных, может не харанится в репозитории и может быть получен из dvc
│   │   ├── iris_dataset.csv.dvc # Мета-аднные модифицированного набора данных
│   │   ├── origin_iris_dataset.csv # Оригинальный набор данных
│   │   └── origin_iris_dataset.csv.dvc # Мета-аднные оригинального набора данных
│   │
│   ├── model/
│   │   ├── rf_clf.pkl # Обученная модель не хранится в репозитории и может быть получена из dvc
│   │   └── rf_clf.pkl.dvc # Мета-данные обученной модели
│   │   
│   │
│   ├── data_preprocessing.py # Скрипт обработки данных
│   ├── load_data.py # Скрипт загрузки данных
│   ├── make_prediction.py # Скрипт предсказания класса объекта
│   ├── model_training.py # Скрипт обучения модели
│   └── requirements.txt # Список необходимых библиотек для корректной работы
│   
│
├── frontend/ # Содержит файлы для работы streamlit 
|    ├── app.py # Скрипт описывающий структуру интерфейса
|    ├── iris.png # Пояснительное изображение
|    └── requirements.txt # Список необходимых библиотек для корректной работы
|    
└── tests/ # Содержит модульные тесты и тест на качество данных и модели
    ├── unit_tests.py # Скрипт содержащий тетсы
    └── requirements.txt # Список необходимых библиотек для корректной работы
```
# Разработка различных аспектов осуществлялась в разных ветках репозитория
```
 | backend/load_data
 | backend/model_training
 | backend/preprocessing
 | deploy/dockerfile
 | final_task/description
 | frontend/interface
 | tests/backend
 | tests/frontend

```
# Версионирование данных
Версионирование данных осуществляется при помощи dvc и google drive

[Google Drive](https://drive.google.com/drive/folders/14BqriGp0xzr83qK3r5Kw5A7FJ2aBk2_s?usp=sharing) на который сохранялись версии
* Доступ к хранилищу осуществлялся при помощи сервисного ключа

# Тесты
* test_load_data - проверяет корректную загрузку исходных данных
* test_data_prep - порверяет качетство обработки данных, а именно стандартизацию mean ≈ 0, std ≈ 1
* test_train_model - тестирует наличие обученной модели в необходимом формате
* test_model_performance - тестирует качетсво данных и работы модели, тетст считается пройденным, если accuracy >= 0.9
* test_app - тестирует корректность работы streamlit интерфейса
* test_model_response - проверяет на соответствие класс объекта, полученного от модели с реальным

# CI/CD
Автоматизация была настроена с использованием Jenkins на виртуальной машине. Стадии пайплайна показаны ниже:
![alt text](https://github.com/NikerAi/mlops_practice/blob/main/final_task/pipeline.png)
**Запуск пайплайна начинается автоматически после пуша в main через webhook**
* clone repo - копирование репозитория
* install requirements - установка всех необходимых библиотек
* pull dvc data - загружает данные и обученную модель из [Google Drive](https://drive.google.com/drive/folders/14BqriGp0xzr83qK3r5Kw5A7FJ2aBk2_s?usp=sharing)
* run tests - запускает тесты
* build image - создает docker образ на основе Dockerfile и назначает имя зависящее от хеша текущего коммита в github
* run docker - запускает собранный образ
